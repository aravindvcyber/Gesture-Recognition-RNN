# Gesture-Recognition-RNN Case study IIITB & Upgrad

This project involves building a 3D Neural Network to correctly recognize hand gestures by a user to control a smart TV.


We need to develop a cool feature in the smart-TV that can recognise five different gestures performed by the user which will help users control the TV without using a remote. 

# Problem Statement:
The objective of this projects is to build a hand gesture recognition model that can be hosted on a camera installed in a smart TV that can understand 5 gestures.   
The gestures are continuously monitored by the webcam mounted on the TV. Each gesture corresponds to a specific command:  
-	Thumbs up:  Increase the volume  
-	Thumbs down: Decrease the volume  
-	Left swipe: 'Jump' backwards 10 seconds  
-	Right swipe: 'Jump' forward 10 seconds    
-	Stop: Pause the movie  

<img width="1555" alt="Screenshot 2024-10-01 at 10 21 57â€¯PM" src="https://github.com/user-attachments/assets/4b33c453-82d1-4bd4-b14a-282e35901668">



# About the Dataset: 
The training data consists of a few hundred videos categorised into one of the five classes. Each video (typically 2-3 seconds long) is divided into a sequence of 30 frames(images). These videos have been recorded by various people performing one of the five gestures in front of a webcam - similar to what the smart TV will use.  
The videos have two types of dimensions - either 360x360 or 120x160 (depending on the webcam used to record the videos).  

Dataset : https://drive.google.com/uc?id=1ehyrYBQ5rbQQe6yL4XbLWe3FMvuVUGiL

https://www.kaggle.com/datasets/aravindvcyber/av-ms-gesture-recognition-project/

 

